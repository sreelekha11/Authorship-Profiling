{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Authorship_Profiling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PEFW5kVH1JtPcxVQX4NL3yBlVm68PGQB",
      "authorship_tag": "ABX9TyPQtvo4kqvZhlhY4zb1zC2U"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c96cd84faa44e96b3b5c1b14cb9416e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8635f1d865ba4205bd328d05c9aa8d99",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c5c6a13ec6bb4c86bca9f43e9e1fe878",
              "IPY_MODEL_fe47abfe04844cd9a6942d7c053e4a64"
            ]
          }
        },
        "8635f1d865ba4205bd328d05c9aa8d99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5c6a13ec6bb4c86bca9f43e9e1fe878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_622968e3cc154ff38a77cdad1ec16ceb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_96979ebcb1864fd682dcfdc2b1edcf05"
          }
        },
        "fe47abfe04844cd9a6942d7c053e4a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45178b692aaf4877aa928c38c237522d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 813kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58751da29415454198ea100509c441d8"
          }
        },
        "622968e3cc154ff38a77cdad1ec16ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "96979ebcb1864fd682dcfdc2b1edcf05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45178b692aaf4877aa928c38c237522d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58751da29415454198ea100509c441d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36a1c705c34143b3a34368eba655995a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61ab45eb6cd1403089eab1fa8f1c22f8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ecf3dbfe6c2f4e46bbb7c22452eba59b",
              "IPY_MODEL_9352f1d9c17f4cee97d2c08afdfabdce"
            ]
          }
        },
        "61ab45eb6cd1403089eab1fa8f1c22f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ecf3dbfe6c2f4e46bbb7c22452eba59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d7d1a2a8a8da4816a171d4df9e96b691",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb7b644740f1459da48b2e069d222859"
          }
        },
        "9352f1d9c17f4cee97d2c08afdfabdce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_197f3e9ad5dd48859c79af1b4e1eca4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 52.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ae59cae1fc6472eb4e0146e2b93ea75"
          }
        },
        "d7d1a2a8a8da4816a171d4df9e96b691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb7b644740f1459da48b2e069d222859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "197f3e9ad5dd48859c79af1b4e1eca4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ae59cae1fc6472eb4e0146e2b93ea75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9992322b86f24bf4a6cdfa98d38f86fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b07e3d5549be4d0c87e5f29e1360ca17",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_55aee13c84194004bbaeb3863d5ae982",
              "IPY_MODEL_2623052d4294410e832c0812cee7313a"
            ]
          }
        },
        "b07e3d5549be4d0c87e5f29e1360ca17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55aee13c84194004bbaeb3863d5ae982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e649b481e27c444099f91f1e79a9cf3c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd2373e0d28343eab72f74469203e5a8"
          }
        },
        "2623052d4294410e832c0812cee7313a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b9c6251df144d0e98a97e13ed1820bd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 59.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_049aebb250f9407eb4451aeb72ebe559"
          }
        },
        "e649b481e27c444099f91f1e79a9cf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd2373e0d28343eab72f74469203e5a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b9c6251df144d0e98a97e13ed1820bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "049aebb250f9407eb4451aeb72ebe559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu-w2jiQh02-",
        "outputId": "31cd18a7-4955-4766-9ca0-94f0668c8b90"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Get the GPU device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "#Device name should look like the following:\n",
        "if device_name == '/device:GPU:0' :\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else :\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAeowzgFil3S",
        "outputId": "61bf73fb-4c7d-4cd5-bf89-fce4500eef81"
      },
      "source": [
        "import torch\n",
        " \n",
        "#if there is a GPU available\n",
        "if torch.cuda.is_available():\n",
        " \n",
        "  #pytorch should use the GPU\n",
        "  device=torch.device(\"cuda\")\n",
        " \n",
        "  print('There are %d GPUs available.'%torch.cuda.device_count())\n",
        " \n",
        "  print('We will use the GPU: ', torch.cuda.get_device_name(0))\n",
        " \n",
        "#if not use CPU instead\n",
        "else:\n",
        "  print('No GPU available. Using CPU instead.')  \n",
        "  device=torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPUs available.\n",
            "We will use the GPU:  Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGqtEweGOpEh",
        "outputId": "c2bb68b5-b743-4dea-b5fa-f46feae0d703"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvhSJDAhjAC6",
        "outputId": "42e54b32-0f28-4bd2-9fdb-c17cad50b0a7"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=aadb2e7d766e6e1394eadb34be56616eda4bebc4b24d5fb977f99c430762e314\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twGXpiWLka_X"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AUTH_PROF_BERT DataSet/bert_train.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxswR-_gxxaZ"
      },
      "source": [
        "ss = df['sentence'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh1OiVn1x4On",
        "outputId": "7df69f24-0f21-4513-d4aa-f66e5b92a0e0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvMyFrYfyATL"
      },
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "\n",
        "ss = [\" \".join([stemmer.stem(word) for word in sentence.split(\" \")]) for sentence in ss]\n",
        "\n",
        "ss = [\" \".join([lemmatizer.lemmatize(word) for word in sentence.split(\" \")]) for sentence in ss]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXf-Zr5EyG-4"
      },
      "source": [
        "df['sentence'] = ss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6sjiWkg_Qh_"
      },
      "source": [
        "df = df[~df['label'].isnull()]\n",
        "df[['label']] = df[['label']].astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "X8A1ELxDyMim",
        "outputId": "39a2d592-378d-4e0c-d0fd-9a0747949bdb"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>272695</th>\n",
              "      <td>fff1359e0dc1eba31a10120bf16834b7.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>hey studio q nzh said yes print abus look legit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272696</th>\n",
              "      <td>fff1359e0dc1eba31a10120bf16834b7.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>god let asswip post self piti piec mother day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272697</th>\n",
              "      <td>fff1359e0dc1eba31a10120bf16834b7.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>week pinch stalk co old timer day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272698</th>\n",
              "      <td>fff1359e0dc1eba31a10120bf16834b7.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>stori relev co timelin know say legit post nz ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272699</th>\n",
              "      <td>fff1359e0dc1eba31a10120bf16834b7.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>rate system launch</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           ID  ...                                           sentence\n",
              "272695  fff1359e0dc1eba31a10120bf16834b7.csv   ...    hey studio q nzh said yes print abus look legit\n",
              "272696  fff1359e0dc1eba31a10120bf16834b7.csv   ...      god let asswip post self piti piec mother day\n",
              "272697  fff1359e0dc1eba31a10120bf16834b7.csv   ...                  week pinch stalk co old timer day\n",
              "272698  fff1359e0dc1eba31a10120bf16834b7.csv   ...  stori relev co timelin know say legit post nz ...\n",
              "272699  fff1359e0dc1eba31a10120bf16834b7.csv   ...                                 rate system launch\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DGeURLt0Haw",
        "outputId": "3ec6c72a-e5a7-4464-cec9-5084704dcba7"
      },
      "source": [
        "df.sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                     tweet\n",
              "1                                           watch avail feb\n",
              "2         complet set box batman minifig find want fig b...\n",
              "3                                          mayb come arrang\n",
              "4              heard numer toyworld number despit warn damn\n",
              "                                ...                        \n",
              "272695      hey studio q nzh said yes print abus look legit\n",
              "272696        god let asswip post self piti piec mother day\n",
              "272697                    week pinch stalk co old timer day\n",
              "272698    stori relev co timelin know say legit post nz ...\n",
              "272699                                   rate system launch\n",
              "Name: sentence, Length: 272700, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PLQTANk0ZNY"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iKEj_Yu0eHc",
        "outputId": "c78bbddb-c7e5-4542-a022-d1246d670449"
      },
      "source": [
        "type(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "1c96cd84faa44e96b3b5c1b14cb9416e",
            "8635f1d865ba4205bd328d05c9aa8d99",
            "c5c6a13ec6bb4c86bca9f43e9e1fe878",
            "fe47abfe04844cd9a6942d7c053e4a64",
            "622968e3cc154ff38a77cdad1ec16ceb",
            "96979ebcb1864fd682dcfdc2b1edcf05",
            "45178b692aaf4877aa928c38c237522d",
            "58751da29415454198ea100509c441d8"
          ]
        },
        "id": "vvd4UzZXC2SI",
        "outputId": "f2c3d666-6054-4f48-eb27-068ccb4dbd9e"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c96cd84faa44e96b3b5c1b14cb9416e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWzkycVbKBSd",
        "outputId": "2ce79daf-d228-43ea-8590-e0a4bbe0b6e5"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[1])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[1]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[1])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  watch avail feb\n",
            "Tokenized:  ['watch', 'avail', 'feb']\n",
            "Token IDs:  [3422, 24608, 13114]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-uBiIgdKLgp",
        "outputId": "7e46d7ef-4152-4907-979d-57261a5180ba"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features  .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  tweet\n",
            "Token IDs: [101, 1056, 28394, 2102, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY-rETSPehlc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f0cfcb-d1b0-4b05-de53-546674afafa6"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-ZoUTNu6OxM"
      },
      "source": [
        "MAX_LEN = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsawakPN6Xdh",
        "outputId": "5dffcaf0-3073-4ce5-dfe7-f17dc9ce497e"
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 50...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa0kuta87nvl"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-Jny_SF7tzu"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27flCSdR7vxO"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcyL7yGI8Kzr"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36a1c705c34143b3a34368eba655995a",
            "61ab45eb6cd1403089eab1fa8f1c22f8",
            "ecf3dbfe6c2f4e46bbb7c22452eba59b",
            "9352f1d9c17f4cee97d2c08afdfabdce",
            "d7d1a2a8a8da4816a171d4df9e96b691",
            "cb7b644740f1459da48b2e069d222859",
            "197f3e9ad5dd48859c79af1b4e1eca4b",
            "1ae59cae1fc6472eb4e0146e2b93ea75",
            "9992322b86f24bf4a6cdfa98d38f86fa",
            "b07e3d5549be4d0c87e5f29e1360ca17",
            "55aee13c84194004bbaeb3863d5ae982",
            "2623052d4294410e832c0812cee7313a",
            "e649b481e27c444099f91f1e79a9cf3c",
            "cd2373e0d28343eab72f74469203e5a8",
            "4b9c6251df144d0e98a97e13ed1820bd",
            "049aebb250f9407eb4451aeb72ebe559"
          ]
        },
        "id": "xbKJ5L9h8UIA",
        "outputId": "4d725e6e-a920-4667-84f1-748fde30336c"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36a1c705c34143b3a34368eba655995a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9992322b86f24bf4a6cdfa98d38f86fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aIIoccb8jPv",
        "outputId": "c938b08e-fc14-4231-b0bb-9a69bfe85325"
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnq55BoB8r0J"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJnzR5ap81yq"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0jCMbJh86Nf"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-dIhXLV8_Pq"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTWavluP9EJh",
        "outputId": "885620ea-fdf2-4edc-e2a1-22f2743c20ee"
      },
      "source": [
        "import random\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  7,670.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  7,670.    Elapsed: 0:00:28.\n",
            "  Batch   120  of  7,670.    Elapsed: 0:00:42.\n",
            "  Batch   160  of  7,670.    Elapsed: 0:00:56.\n",
            "  Batch   200  of  7,670.    Elapsed: 0:01:10.\n",
            "  Batch   240  of  7,670.    Elapsed: 0:01:24.\n",
            "  Batch   280  of  7,670.    Elapsed: 0:01:38.\n",
            "  Batch   320  of  7,670.    Elapsed: 0:01:52.\n",
            "  Batch   360  of  7,670.    Elapsed: 0:02:06.\n",
            "  Batch   400  of  7,670.    Elapsed: 0:02:20.\n",
            "  Batch   440  of  7,670.    Elapsed: 0:02:34.\n",
            "  Batch   480  of  7,670.    Elapsed: 0:02:49.\n",
            "  Batch   520  of  7,670.    Elapsed: 0:03:03.\n",
            "  Batch   560  of  7,670.    Elapsed: 0:03:17.\n",
            "  Batch   600  of  7,670.    Elapsed: 0:03:31.\n",
            "  Batch   640  of  7,670.    Elapsed: 0:03:45.\n",
            "  Batch   680  of  7,670.    Elapsed: 0:03:59.\n",
            "  Batch   720  of  7,670.    Elapsed: 0:04:13.\n",
            "  Batch   760  of  7,670.    Elapsed: 0:04:27.\n",
            "  Batch   800  of  7,670.    Elapsed: 0:04:41.\n",
            "  Batch   840  of  7,670.    Elapsed: 0:04:55.\n",
            "  Batch   880  of  7,670.    Elapsed: 0:05:09.\n",
            "  Batch   920  of  7,670.    Elapsed: 0:05:23.\n",
            "  Batch   960  of  7,670.    Elapsed: 0:05:37.\n",
            "  Batch 1,000  of  7,670.    Elapsed: 0:05:52.\n",
            "  Batch 1,040  of  7,670.    Elapsed: 0:06:06.\n",
            "  Batch 1,080  of  7,670.    Elapsed: 0:06:20.\n",
            "  Batch 1,120  of  7,670.    Elapsed: 0:06:34.\n",
            "  Batch 1,160  of  7,670.    Elapsed: 0:06:48.\n",
            "  Batch 1,200  of  7,670.    Elapsed: 0:07:02.\n",
            "  Batch 1,240  of  7,670.    Elapsed: 0:07:16.\n",
            "  Batch 1,280  of  7,670.    Elapsed: 0:07:30.\n",
            "  Batch 1,320  of  7,670.    Elapsed: 0:07:44.\n",
            "  Batch 1,360  of  7,670.    Elapsed: 0:07:58.\n",
            "  Batch 1,400  of  7,670.    Elapsed: 0:08:12.\n",
            "  Batch 1,440  of  7,670.    Elapsed: 0:08:26.\n",
            "  Batch 1,480  of  7,670.    Elapsed: 0:08:41.\n",
            "  Batch 1,520  of  7,670.    Elapsed: 0:08:55.\n",
            "  Batch 1,560  of  7,670.    Elapsed: 0:09:09.\n",
            "  Batch 1,600  of  7,670.    Elapsed: 0:09:23.\n",
            "  Batch 1,640  of  7,670.    Elapsed: 0:09:37.\n",
            "  Batch 1,680  of  7,670.    Elapsed: 0:09:51.\n",
            "  Batch 1,720  of  7,670.    Elapsed: 0:10:05.\n",
            "  Batch 1,760  of  7,670.    Elapsed: 0:10:19.\n",
            "  Batch 1,800  of  7,670.    Elapsed: 0:10:33.\n",
            "  Batch 1,840  of  7,670.    Elapsed: 0:10:47.\n",
            "  Batch 1,880  of  7,670.    Elapsed: 0:11:01.\n",
            "  Batch 1,920  of  7,670.    Elapsed: 0:11:15.\n",
            "  Batch 1,960  of  7,670.    Elapsed: 0:11:30.\n",
            "  Batch 2,000  of  7,670.    Elapsed: 0:11:44.\n",
            "  Batch 2,040  of  7,670.    Elapsed: 0:11:58.\n",
            "  Batch 2,080  of  7,670.    Elapsed: 0:12:12.\n",
            "  Batch 2,120  of  7,670.    Elapsed: 0:12:26.\n",
            "  Batch 2,160  of  7,670.    Elapsed: 0:12:40.\n",
            "  Batch 2,200  of  7,670.    Elapsed: 0:12:54.\n",
            "  Batch 2,240  of  7,670.    Elapsed: 0:13:08.\n",
            "  Batch 2,280  of  7,670.    Elapsed: 0:13:22.\n",
            "  Batch 2,320  of  7,670.    Elapsed: 0:13:36.\n",
            "  Batch 2,360  of  7,670.    Elapsed: 0:13:50.\n",
            "  Batch 2,400  of  7,670.    Elapsed: 0:14:05.\n",
            "  Batch 2,440  of  7,670.    Elapsed: 0:14:19.\n",
            "  Batch 2,480  of  7,670.    Elapsed: 0:14:33.\n",
            "  Batch 2,520  of  7,670.    Elapsed: 0:14:47.\n",
            "  Batch 2,560  of  7,670.    Elapsed: 0:15:01.\n",
            "  Batch 2,600  of  7,670.    Elapsed: 0:15:15.\n",
            "  Batch 2,640  of  7,670.    Elapsed: 0:15:29.\n",
            "  Batch 2,680  of  7,670.    Elapsed: 0:15:43.\n",
            "  Batch 2,720  of  7,670.    Elapsed: 0:15:57.\n",
            "  Batch 2,760  of  7,670.    Elapsed: 0:16:12.\n",
            "  Batch 2,800  of  7,670.    Elapsed: 0:16:26.\n",
            "  Batch 2,840  of  7,670.    Elapsed: 0:16:40.\n",
            "  Batch 2,880  of  7,670.    Elapsed: 0:16:54.\n",
            "  Batch 2,920  of  7,670.    Elapsed: 0:17:08.\n",
            "  Batch 2,960  of  7,670.    Elapsed: 0:17:22.\n",
            "  Batch 3,000  of  7,670.    Elapsed: 0:17:36.\n",
            "  Batch 3,040  of  7,670.    Elapsed: 0:17:50.\n",
            "  Batch 3,080  of  7,670.    Elapsed: 0:18:04.\n",
            "  Batch 3,120  of  7,670.    Elapsed: 0:18:18.\n",
            "  Batch 3,160  of  7,670.    Elapsed: 0:18:33.\n",
            "  Batch 3,200  of  7,670.    Elapsed: 0:18:47.\n",
            "  Batch 3,240  of  7,670.    Elapsed: 0:19:01.\n",
            "  Batch 3,280  of  7,670.    Elapsed: 0:19:15.\n",
            "  Batch 3,320  of  7,670.    Elapsed: 0:19:29.\n",
            "  Batch 3,360  of  7,670.    Elapsed: 0:19:43.\n",
            "  Batch 3,400  of  7,670.    Elapsed: 0:19:57.\n",
            "  Batch 3,440  of  7,670.    Elapsed: 0:20:11.\n",
            "  Batch 3,480  of  7,670.    Elapsed: 0:20:25.\n",
            "  Batch 3,520  of  7,670.    Elapsed: 0:20:39.\n",
            "  Batch 3,560  of  7,670.    Elapsed: 0:20:53.\n",
            "  Batch 3,600  of  7,670.    Elapsed: 0:21:08.\n",
            "  Batch 3,640  of  7,670.    Elapsed: 0:21:22.\n",
            "  Batch 3,680  of  7,670.    Elapsed: 0:21:36.\n",
            "  Batch 3,720  of  7,670.    Elapsed: 0:21:50.\n",
            "  Batch 3,760  of  7,670.    Elapsed: 0:22:04.\n",
            "  Batch 3,800  of  7,670.    Elapsed: 0:22:18.\n",
            "  Batch 3,840  of  7,670.    Elapsed: 0:22:32.\n",
            "  Batch 3,880  of  7,670.    Elapsed: 0:22:46.\n",
            "  Batch 3,920  of  7,670.    Elapsed: 0:23:00.\n",
            "  Batch 3,960  of  7,670.    Elapsed: 0:23:14.\n",
            "  Batch 4,000  of  7,670.    Elapsed: 0:23:28.\n",
            "  Batch 4,040  of  7,670.    Elapsed: 0:23:42.\n",
            "  Batch 4,080  of  7,670.    Elapsed: 0:23:56.\n",
            "  Batch 4,120  of  7,670.    Elapsed: 0:24:11.\n",
            "  Batch 4,160  of  7,670.    Elapsed: 0:24:25.\n",
            "  Batch 4,200  of  7,670.    Elapsed: 0:24:39.\n",
            "  Batch 4,240  of  7,670.    Elapsed: 0:24:53.\n",
            "  Batch 4,280  of  7,670.    Elapsed: 0:25:07.\n",
            "  Batch 4,320  of  7,670.    Elapsed: 0:25:21.\n",
            "  Batch 4,360  of  7,670.    Elapsed: 0:25:35.\n",
            "  Batch 4,400  of  7,670.    Elapsed: 0:25:49.\n",
            "  Batch 4,440  of  7,670.    Elapsed: 0:26:03.\n",
            "  Batch 4,480  of  7,670.    Elapsed: 0:26:17.\n",
            "  Batch 4,520  of  7,670.    Elapsed: 0:26:31.\n",
            "  Batch 4,560  of  7,670.    Elapsed: 0:26:45.\n",
            "  Batch 4,600  of  7,670.    Elapsed: 0:27:00.\n",
            "  Batch 4,640  of  7,670.    Elapsed: 0:27:14.\n",
            "  Batch 4,680  of  7,670.    Elapsed: 0:27:28.\n",
            "  Batch 4,720  of  7,670.    Elapsed: 0:27:42.\n",
            "  Batch 4,760  of  7,670.    Elapsed: 0:27:56.\n",
            "  Batch 4,800  of  7,670.    Elapsed: 0:28:10.\n",
            "  Batch 4,840  of  7,670.    Elapsed: 0:28:24.\n",
            "  Batch 4,880  of  7,670.    Elapsed: 0:28:38.\n",
            "  Batch 4,920  of  7,670.    Elapsed: 0:28:52.\n",
            "  Batch 4,960  of  7,670.    Elapsed: 0:29:06.\n",
            "  Batch 5,000  of  7,670.    Elapsed: 0:29:20.\n",
            "  Batch 5,040  of  7,670.    Elapsed: 0:29:35.\n",
            "  Batch 5,080  of  7,670.    Elapsed: 0:29:49.\n",
            "  Batch 5,120  of  7,670.    Elapsed: 0:30:03.\n",
            "  Batch 5,160  of  7,670.    Elapsed: 0:30:17.\n",
            "  Batch 5,200  of  7,670.    Elapsed: 0:30:31.\n",
            "  Batch 5,240  of  7,670.    Elapsed: 0:30:45.\n",
            "  Batch 5,280  of  7,670.    Elapsed: 0:30:59.\n",
            "  Batch 5,320  of  7,670.    Elapsed: 0:31:13.\n",
            "  Batch 5,360  of  7,670.    Elapsed: 0:31:27.\n",
            "  Batch 5,400  of  7,670.    Elapsed: 0:31:41.\n",
            "  Batch 5,440  of  7,670.    Elapsed: 0:31:55.\n",
            "  Batch 5,480  of  7,670.    Elapsed: 0:32:09.\n",
            "  Batch 5,520  of  7,670.    Elapsed: 0:32:23.\n",
            "  Batch 5,560  of  7,670.    Elapsed: 0:32:38.\n",
            "  Batch 5,600  of  7,670.    Elapsed: 0:32:52.\n",
            "  Batch 5,640  of  7,670.    Elapsed: 0:33:06.\n",
            "  Batch 5,680  of  7,670.    Elapsed: 0:33:20.\n",
            "  Batch 5,720  of  7,670.    Elapsed: 0:33:34.\n",
            "  Batch 5,760  of  7,670.    Elapsed: 0:33:48.\n",
            "  Batch 5,800  of  7,670.    Elapsed: 0:34:02.\n",
            "  Batch 5,840  of  7,670.    Elapsed: 0:34:16.\n",
            "  Batch 5,880  of  7,670.    Elapsed: 0:34:30.\n",
            "  Batch 5,920  of  7,670.    Elapsed: 0:34:44.\n",
            "  Batch 5,960  of  7,670.    Elapsed: 0:34:58.\n",
            "  Batch 6,000  of  7,670.    Elapsed: 0:35:13.\n",
            "  Batch 6,040  of  7,670.    Elapsed: 0:35:27.\n",
            "  Batch 6,080  of  7,670.    Elapsed: 0:35:41.\n",
            "  Batch 6,120  of  7,670.    Elapsed: 0:35:55.\n",
            "  Batch 6,160  of  7,670.    Elapsed: 0:36:09.\n",
            "  Batch 6,200  of  7,670.    Elapsed: 0:36:23.\n",
            "  Batch 6,240  of  7,670.    Elapsed: 0:36:37.\n",
            "  Batch 6,280  of  7,670.    Elapsed: 0:36:51.\n",
            "  Batch 6,320  of  7,670.    Elapsed: 0:37:05.\n",
            "  Batch 6,360  of  7,670.    Elapsed: 0:37:19.\n",
            "  Batch 6,400  of  7,670.    Elapsed: 0:37:33.\n",
            "  Batch 6,440  of  7,670.    Elapsed: 0:37:48.\n",
            "  Batch 6,480  of  7,670.    Elapsed: 0:38:02.\n",
            "  Batch 6,520  of  7,670.    Elapsed: 0:38:16.\n",
            "  Batch 6,560  of  7,670.    Elapsed: 0:38:30.\n",
            "  Batch 6,600  of  7,670.    Elapsed: 0:38:44.\n",
            "  Batch 6,640  of  7,670.    Elapsed: 0:38:58.\n",
            "  Batch 6,680  of  7,670.    Elapsed: 0:39:12.\n",
            "  Batch 6,720  of  7,670.    Elapsed: 0:39:26.\n",
            "  Batch 6,760  of  7,670.    Elapsed: 0:39:40.\n",
            "  Batch 6,800  of  7,670.    Elapsed: 0:39:54.\n",
            "  Batch 6,840  of  7,670.    Elapsed: 0:40:08.\n",
            "  Batch 6,880  of  7,670.    Elapsed: 0:40:22.\n",
            "  Batch 6,920  of  7,670.    Elapsed: 0:40:37.\n",
            "  Batch 6,960  of  7,670.    Elapsed: 0:40:51.\n",
            "  Batch 7,000  of  7,670.    Elapsed: 0:41:05.\n",
            "  Batch 7,040  of  7,670.    Elapsed: 0:41:19.\n",
            "  Batch 7,080  of  7,670.    Elapsed: 0:41:33.\n",
            "  Batch 7,120  of  7,670.    Elapsed: 0:41:47.\n",
            "  Batch 7,160  of  7,670.    Elapsed: 0:42:01.\n",
            "  Batch 7,200  of  7,670.    Elapsed: 0:42:15.\n",
            "  Batch 7,240  of  7,670.    Elapsed: 0:42:29.\n",
            "  Batch 7,280  of  7,670.    Elapsed: 0:42:43.\n",
            "  Batch 7,320  of  7,670.    Elapsed: 0:42:58.\n",
            "  Batch 7,360  of  7,670.    Elapsed: 0:43:12.\n",
            "  Batch 7,400  of  7,670.    Elapsed: 0:43:26.\n",
            "  Batch 7,440  of  7,670.    Elapsed: 0:43:40.\n",
            "  Batch 7,480  of  7,670.    Elapsed: 0:43:54.\n",
            "  Batch 7,520  of  7,670.    Elapsed: 0:44:08.\n",
            "  Batch 7,560  of  7,670.    Elapsed: 0:44:22.\n",
            "  Batch 7,600  of  7,670.    Elapsed: 0:44:36.\n",
            "  Batch 7,640  of  7,670.    Elapsed: 0:44:50.\n",
            "\n",
            "  Average training loss: 0.66\n",
            "  Training epcoh took: 0:45:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation took: 0:01:37\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  7,670.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  7,670.    Elapsed: 0:00:28.\n",
            "  Batch   120  of  7,670.    Elapsed: 0:00:42.\n",
            "  Batch   160  of  7,670.    Elapsed: 0:00:56.\n",
            "  Batch   200  of  7,670.    Elapsed: 0:01:10.\n",
            "  Batch   240  of  7,670.    Elapsed: 0:01:25.\n",
            "  Batch   280  of  7,670.    Elapsed: 0:01:39.\n",
            "  Batch   320  of  7,670.    Elapsed: 0:01:53.\n",
            "  Batch   360  of  7,670.    Elapsed: 0:02:07.\n",
            "  Batch   400  of  7,670.    Elapsed: 0:02:21.\n",
            "  Batch   440  of  7,670.    Elapsed: 0:02:35.\n",
            "  Batch   480  of  7,670.    Elapsed: 0:02:49.\n",
            "  Batch   520  of  7,670.    Elapsed: 0:03:03.\n",
            "  Batch   560  of  7,670.    Elapsed: 0:03:17.\n",
            "  Batch   600  of  7,670.    Elapsed: 0:03:31.\n",
            "  Batch   640  of  7,670.    Elapsed: 0:03:46.\n",
            "  Batch   680  of  7,670.    Elapsed: 0:04:00.\n",
            "  Batch   720  of  7,670.    Elapsed: 0:04:14.\n",
            "  Batch   760  of  7,670.    Elapsed: 0:04:28.\n",
            "  Batch   800  of  7,670.    Elapsed: 0:04:42.\n",
            "  Batch   840  of  7,670.    Elapsed: 0:04:56.\n",
            "  Batch   880  of  7,670.    Elapsed: 0:05:10.\n",
            "  Batch   920  of  7,670.    Elapsed: 0:05:24.\n",
            "  Batch   960  of  7,670.    Elapsed: 0:05:38.\n",
            "  Batch 1,000  of  7,670.    Elapsed: 0:05:52.\n",
            "  Batch 1,040  of  7,670.    Elapsed: 0:06:06.\n",
            "  Batch 1,080  of  7,670.    Elapsed: 0:06:21.\n",
            "  Batch 1,120  of  7,670.    Elapsed: 0:06:35.\n",
            "  Batch 1,160  of  7,670.    Elapsed: 0:06:49.\n",
            "  Batch 1,200  of  7,670.    Elapsed: 0:07:03.\n",
            "  Batch 1,240  of  7,670.    Elapsed: 0:07:17.\n",
            "  Batch 1,280  of  7,670.    Elapsed: 0:07:31.\n",
            "  Batch 1,320  of  7,670.    Elapsed: 0:07:45.\n",
            "  Batch 1,360  of  7,670.    Elapsed: 0:07:59.\n",
            "  Batch 1,400  of  7,670.    Elapsed: 0:08:13.\n",
            "  Batch 1,440  of  7,670.    Elapsed: 0:08:27.\n",
            "  Batch 1,480  of  7,670.    Elapsed: 0:08:41.\n",
            "  Batch 1,520  of  7,670.    Elapsed: 0:08:55.\n",
            "  Batch 1,560  of  7,670.    Elapsed: 0:09:09.\n",
            "  Batch 1,600  of  7,670.    Elapsed: 0:09:24.\n",
            "  Batch 1,640  of  7,670.    Elapsed: 0:09:38.\n",
            "  Batch 1,680  of  7,670.    Elapsed: 0:09:52.\n",
            "  Batch 1,720  of  7,670.    Elapsed: 0:10:06.\n",
            "  Batch 1,760  of  7,670.    Elapsed: 0:10:20.\n",
            "  Batch 1,800  of  7,670.    Elapsed: 0:10:34.\n",
            "  Batch 1,840  of  7,670.    Elapsed: 0:10:48.\n",
            "  Batch 1,880  of  7,670.    Elapsed: 0:11:02.\n",
            "  Batch 1,920  of  7,670.    Elapsed: 0:11:16.\n",
            "  Batch 1,960  of  7,670.    Elapsed: 0:11:30.\n",
            "  Batch 2,000  of  7,670.    Elapsed: 0:11:44.\n",
            "  Batch 2,040  of  7,670.    Elapsed: 0:11:58.\n",
            "  Batch 2,080  of  7,670.    Elapsed: 0:12:12.\n",
            "  Batch 2,120  of  7,670.    Elapsed: 0:12:27.\n",
            "  Batch 2,160  of  7,670.    Elapsed: 0:12:41.\n",
            "  Batch 2,200  of  7,670.    Elapsed: 0:12:55.\n",
            "  Batch 2,240  of  7,670.    Elapsed: 0:13:09.\n",
            "  Batch 2,280  of  7,670.    Elapsed: 0:13:23.\n",
            "  Batch 2,320  of  7,670.    Elapsed: 0:13:37.\n",
            "  Batch 2,360  of  7,670.    Elapsed: 0:13:51.\n",
            "  Batch 2,400  of  7,670.    Elapsed: 0:14:05.\n",
            "  Batch 2,440  of  7,670.    Elapsed: 0:14:19.\n",
            "  Batch 2,480  of  7,670.    Elapsed: 0:14:33.\n",
            "  Batch 2,520  of  7,670.    Elapsed: 0:14:47.\n",
            "  Batch 2,560  of  7,670.    Elapsed: 0:15:01.\n",
            "  Batch 2,600  of  7,670.    Elapsed: 0:15:16.\n",
            "  Batch 2,640  of  7,670.    Elapsed: 0:15:30.\n",
            "  Batch 2,680  of  7,670.    Elapsed: 0:15:44.\n",
            "  Batch 2,720  of  7,670.    Elapsed: 0:15:58.\n",
            "  Batch 2,760  of  7,670.    Elapsed: 0:16:12.\n",
            "  Batch 2,800  of  7,670.    Elapsed: 0:16:26.\n",
            "  Batch 2,840  of  7,670.    Elapsed: 0:16:40.\n",
            "  Batch 2,880  of  7,670.    Elapsed: 0:16:54.\n",
            "  Batch 2,920  of  7,670.    Elapsed: 0:17:08.\n",
            "  Batch 2,960  of  7,670.    Elapsed: 0:17:22.\n",
            "  Batch 3,000  of  7,670.    Elapsed: 0:17:36.\n",
            "  Batch 3,040  of  7,670.    Elapsed: 0:17:50.\n",
            "  Batch 3,080  of  7,670.    Elapsed: 0:18:05.\n",
            "  Batch 3,120  of  7,670.    Elapsed: 0:18:19.\n",
            "  Batch 3,160  of  7,670.    Elapsed: 0:18:33.\n",
            "  Batch 3,200  of  7,670.    Elapsed: 0:18:47.\n",
            "  Batch 3,240  of  7,670.    Elapsed: 0:19:01.\n",
            "  Batch 3,280  of  7,670.    Elapsed: 0:19:15.\n",
            "  Batch 3,320  of  7,670.    Elapsed: 0:19:29.\n",
            "  Batch 3,360  of  7,670.    Elapsed: 0:19:43.\n",
            "  Batch 3,400  of  7,670.    Elapsed: 0:19:57.\n",
            "  Batch 3,440  of  7,670.    Elapsed: 0:20:11.\n",
            "  Batch 3,480  of  7,670.    Elapsed: 0:20:25.\n",
            "  Batch 3,520  of  7,670.    Elapsed: 0:20:39.\n",
            "  Batch 3,560  of  7,670.    Elapsed: 0:20:54.\n",
            "  Batch 3,600  of  7,670.    Elapsed: 0:21:08.\n",
            "  Batch 3,640  of  7,670.    Elapsed: 0:21:22.\n",
            "  Batch 3,680  of  7,670.    Elapsed: 0:21:36.\n",
            "  Batch 3,720  of  7,670.    Elapsed: 0:21:50.\n",
            "  Batch 3,760  of  7,670.    Elapsed: 0:22:04.\n",
            "  Batch 3,800  of  7,670.    Elapsed: 0:22:18.\n",
            "  Batch 3,840  of  7,670.    Elapsed: 0:22:32.\n",
            "  Batch 3,880  of  7,670.    Elapsed: 0:22:46.\n",
            "  Batch 3,920  of  7,670.    Elapsed: 0:23:00.\n",
            "  Batch 3,960  of  7,670.    Elapsed: 0:23:14.\n",
            "  Batch 4,000  of  7,670.    Elapsed: 0:23:28.\n",
            "  Batch 4,040  of  7,670.    Elapsed: 0:23:42.\n",
            "  Batch 4,080  of  7,670.    Elapsed: 0:23:57.\n",
            "  Batch 4,120  of  7,670.    Elapsed: 0:24:11.\n",
            "  Batch 4,160  of  7,670.    Elapsed: 0:24:25.\n",
            "  Batch 4,200  of  7,670.    Elapsed: 0:24:39.\n",
            "  Batch 4,240  of  7,670.    Elapsed: 0:24:53.\n",
            "  Batch 4,280  of  7,670.    Elapsed: 0:25:07.\n",
            "  Batch 4,320  of  7,670.    Elapsed: 0:25:21.\n",
            "  Batch 4,360  of  7,670.    Elapsed: 0:25:35.\n",
            "  Batch 4,400  of  7,670.    Elapsed: 0:25:49.\n",
            "  Batch 4,440  of  7,670.    Elapsed: 0:26:03.\n",
            "  Batch 4,480  of  7,670.    Elapsed: 0:26:17.\n",
            "  Batch 4,520  of  7,670.    Elapsed: 0:26:31.\n",
            "  Batch 4,560  of  7,670.    Elapsed: 0:26:46.\n",
            "  Batch 4,600  of  7,670.    Elapsed: 0:27:00.\n",
            "  Batch 4,640  of  7,670.    Elapsed: 0:27:14.\n",
            "  Batch 4,680  of  7,670.    Elapsed: 0:27:28.\n",
            "  Batch 4,720  of  7,670.    Elapsed: 0:27:42.\n",
            "  Batch 4,760  of  7,670.    Elapsed: 0:27:56.\n",
            "  Batch 4,800  of  7,670.    Elapsed: 0:28:10.\n",
            "  Batch 4,840  of  7,670.    Elapsed: 0:28:24.\n",
            "  Batch 4,880  of  7,670.    Elapsed: 0:28:38.\n",
            "  Batch 4,920  of  7,670.    Elapsed: 0:28:53.\n",
            "  Batch 4,960  of  7,670.    Elapsed: 0:29:07.\n",
            "  Batch 5,000  of  7,670.    Elapsed: 0:29:21.\n",
            "  Batch 5,040  of  7,670.    Elapsed: 0:29:35.\n",
            "  Batch 5,080  of  7,670.    Elapsed: 0:29:49.\n",
            "  Batch 5,120  of  7,670.    Elapsed: 0:30:03.\n",
            "  Batch 5,160  of  7,670.    Elapsed: 0:30:17.\n",
            "  Batch 5,200  of  7,670.    Elapsed: 0:30:31.\n",
            "  Batch 5,240  of  7,670.    Elapsed: 0:30:45.\n",
            "  Batch 5,280  of  7,670.    Elapsed: 0:30:59.\n",
            "  Batch 5,320  of  7,670.    Elapsed: 0:31:13.\n",
            "  Batch 5,360  of  7,670.    Elapsed: 0:31:28.\n",
            "  Batch 5,400  of  7,670.    Elapsed: 0:31:42.\n",
            "  Batch 5,440  of  7,670.    Elapsed: 0:31:56.\n",
            "  Batch 5,480  of  7,670.    Elapsed: 0:32:10.\n",
            "  Batch 5,520  of  7,670.    Elapsed: 0:32:24.\n",
            "  Batch 5,560  of  7,670.    Elapsed: 0:32:38.\n",
            "  Batch 5,600  of  7,670.    Elapsed: 0:32:52.\n",
            "  Batch 5,640  of  7,670.    Elapsed: 0:33:06.\n",
            "  Batch 5,680  of  7,670.    Elapsed: 0:33:20.\n",
            "  Batch 5,720  of  7,670.    Elapsed: 0:33:34.\n",
            "  Batch 5,760  of  7,670.    Elapsed: 0:33:48.\n",
            "  Batch 5,800  of  7,670.    Elapsed: 0:34:03.\n",
            "  Batch 5,840  of  7,670.    Elapsed: 0:34:17.\n",
            "  Batch 5,880  of  7,670.    Elapsed: 0:34:31.\n",
            "  Batch 5,920  of  7,670.    Elapsed: 0:34:45.\n",
            "  Batch 5,960  of  7,670.    Elapsed: 0:34:59.\n",
            "  Batch 6,000  of  7,670.    Elapsed: 0:35:13.\n",
            "  Batch 6,040  of  7,670.    Elapsed: 0:35:27.\n",
            "  Batch 6,080  of  7,670.    Elapsed: 0:35:41.\n",
            "  Batch 6,120  of  7,670.    Elapsed: 0:35:55.\n",
            "  Batch 6,160  of  7,670.    Elapsed: 0:36:10.\n",
            "  Batch 6,200  of  7,670.    Elapsed: 0:36:24.\n",
            "  Batch 6,240  of  7,670.    Elapsed: 0:36:38.\n",
            "  Batch 6,280  of  7,670.    Elapsed: 0:36:52.\n",
            "  Batch 6,320  of  7,670.    Elapsed: 0:37:06.\n",
            "  Batch 6,360  of  7,670.    Elapsed: 0:37:20.\n",
            "  Batch 6,400  of  7,670.    Elapsed: 0:37:34.\n",
            "  Batch 6,440  of  7,670.    Elapsed: 0:37:48.\n",
            "  Batch 6,480  of  7,670.    Elapsed: 0:38:02.\n",
            "  Batch 6,520  of  7,670.    Elapsed: 0:38:17.\n",
            "  Batch 6,560  of  7,670.    Elapsed: 0:38:31.\n",
            "  Batch 6,600  of  7,670.    Elapsed: 0:38:45.\n",
            "  Batch 6,640  of  7,670.    Elapsed: 0:38:59.\n",
            "  Batch 6,680  of  7,670.    Elapsed: 0:39:13.\n",
            "  Batch 6,720  of  7,670.    Elapsed: 0:39:27.\n",
            "  Batch 6,760  of  7,670.    Elapsed: 0:39:41.\n",
            "  Batch 6,800  of  7,670.    Elapsed: 0:39:55.\n",
            "  Batch 6,840  of  7,670.    Elapsed: 0:40:10.\n",
            "  Batch 6,880  of  7,670.    Elapsed: 0:40:24.\n",
            "  Batch 6,920  of  7,670.    Elapsed: 0:40:38.\n",
            "  Batch 6,960  of  7,670.    Elapsed: 0:40:52.\n",
            "  Batch 7,000  of  7,670.    Elapsed: 0:41:06.\n",
            "  Batch 7,040  of  7,670.    Elapsed: 0:41:20.\n",
            "  Batch 7,080  of  7,670.    Elapsed: 0:41:34.\n",
            "  Batch 7,120  of  7,670.    Elapsed: 0:41:48.\n",
            "  Batch 7,160  of  7,670.    Elapsed: 0:42:02.\n",
            "  Batch 7,200  of  7,670.    Elapsed: 0:42:17.\n",
            "  Batch 7,240  of  7,670.    Elapsed: 0:42:31.\n",
            "  Batch 7,280  of  7,670.    Elapsed: 0:42:45.\n",
            "  Batch 7,320  of  7,670.    Elapsed: 0:42:59.\n",
            "  Batch 7,360  of  7,670.    Elapsed: 0:43:13.\n",
            "  Batch 7,400  of  7,670.    Elapsed: 0:43:27.\n",
            "  Batch 7,440  of  7,670.    Elapsed: 0:43:41.\n",
            "  Batch 7,480  of  7,670.    Elapsed: 0:43:55.\n",
            "  Batch 7,520  of  7,670.    Elapsed: 0:44:09.\n",
            "  Batch 7,560  of  7,670.    Elapsed: 0:44:23.\n",
            "  Batch 7,600  of  7,670.    Elapsed: 0:44:38.\n",
            "  Batch 7,640  of  7,670.    Elapsed: 0:44:52.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:45:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation took: 0:01:37\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  7,670.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  7,670.    Elapsed: 0:00:28.\n",
            "  Batch   120  of  7,670.    Elapsed: 0:00:42.\n",
            "  Batch   160  of  7,670.    Elapsed: 0:00:56.\n",
            "  Batch   200  of  7,670.    Elapsed: 0:01:11.\n",
            "  Batch   240  of  7,670.    Elapsed: 0:01:25.\n",
            "  Batch   280  of  7,670.    Elapsed: 0:01:39.\n",
            "  Batch   320  of  7,670.    Elapsed: 0:01:53.\n",
            "  Batch   360  of  7,670.    Elapsed: 0:02:07.\n",
            "  Batch   400  of  7,670.    Elapsed: 0:02:21.\n",
            "  Batch   440  of  7,670.    Elapsed: 0:02:35.\n",
            "  Batch   480  of  7,670.    Elapsed: 0:02:49.\n",
            "  Batch   520  of  7,670.    Elapsed: 0:03:03.\n",
            "  Batch   560  of  7,670.    Elapsed: 0:03:17.\n",
            "  Batch   600  of  7,670.    Elapsed: 0:03:31.\n",
            "  Batch   640  of  7,670.    Elapsed: 0:03:45.\n",
            "  Batch   680  of  7,670.    Elapsed: 0:04:00.\n",
            "  Batch   720  of  7,670.    Elapsed: 0:04:14.\n",
            "  Batch   760  of  7,670.    Elapsed: 0:04:28.\n",
            "  Batch   800  of  7,670.    Elapsed: 0:04:42.\n",
            "  Batch   840  of  7,670.    Elapsed: 0:04:56.\n",
            "  Batch   880  of  7,670.    Elapsed: 0:05:10.\n",
            "  Batch   920  of  7,670.    Elapsed: 0:05:24.\n",
            "  Batch   960  of  7,670.    Elapsed: 0:05:38.\n",
            "  Batch 1,000  of  7,670.    Elapsed: 0:05:52.\n",
            "  Batch 1,040  of  7,670.    Elapsed: 0:06:06.\n",
            "  Batch 1,080  of  7,670.    Elapsed: 0:06:20.\n",
            "  Batch 1,120  of  7,670.    Elapsed: 0:06:34.\n",
            "  Batch 1,160  of  7,670.    Elapsed: 0:06:49.\n",
            "  Batch 1,200  of  7,670.    Elapsed: 0:07:03.\n",
            "  Batch 1,240  of  7,670.    Elapsed: 0:07:17.\n",
            "  Batch 1,280  of  7,670.    Elapsed: 0:07:31.\n",
            "  Batch 1,320  of  7,670.    Elapsed: 0:07:45.\n",
            "  Batch 1,360  of  7,670.    Elapsed: 0:07:59.\n",
            "  Batch 1,400  of  7,670.    Elapsed: 0:08:13.\n",
            "  Batch 1,440  of  7,670.    Elapsed: 0:08:27.\n",
            "  Batch 1,480  of  7,670.    Elapsed: 0:08:41.\n",
            "  Batch 1,520  of  7,670.    Elapsed: 0:08:55.\n",
            "  Batch 1,560  of  7,670.    Elapsed: 0:09:09.\n",
            "  Batch 1,600  of  7,670.    Elapsed: 0:09:23.\n",
            "  Batch 1,640  of  7,670.    Elapsed: 0:09:37.\n",
            "  Batch 1,680  of  7,670.    Elapsed: 0:09:52.\n",
            "  Batch 1,720  of  7,670.    Elapsed: 0:10:06.\n",
            "  Batch 1,760  of  7,670.    Elapsed: 0:10:20.\n",
            "  Batch 1,800  of  7,670.    Elapsed: 0:10:34.\n",
            "  Batch 1,840  of  7,670.    Elapsed: 0:10:48.\n",
            "  Batch 1,880  of  7,670.    Elapsed: 0:11:02.\n",
            "  Batch 1,920  of  7,670.    Elapsed: 0:11:16.\n",
            "  Batch 1,960  of  7,670.    Elapsed: 0:11:30.\n",
            "  Batch 2,000  of  7,670.    Elapsed: 0:11:44.\n",
            "  Batch 2,040  of  7,670.    Elapsed: 0:11:58.\n",
            "  Batch 2,080  of  7,670.    Elapsed: 0:12:12.\n",
            "  Batch 2,120  of  7,670.    Elapsed: 0:12:26.\n",
            "  Batch 2,160  of  7,670.    Elapsed: 0:12:40.\n",
            "  Batch 2,200  of  7,670.    Elapsed: 0:12:55.\n",
            "  Batch 2,240  of  7,670.    Elapsed: 0:13:09.\n",
            "  Batch 2,280  of  7,670.    Elapsed: 0:13:23.\n",
            "  Batch 2,320  of  7,670.    Elapsed: 0:13:37.\n",
            "  Batch 2,360  of  7,670.    Elapsed: 0:13:51.\n",
            "  Batch 2,400  of  7,670.    Elapsed: 0:14:05.\n",
            "  Batch 2,440  of  7,670.    Elapsed: 0:14:19.\n",
            "  Batch 2,480  of  7,670.    Elapsed: 0:14:33.\n",
            "  Batch 2,520  of  7,670.    Elapsed: 0:14:47.\n",
            "  Batch 2,560  of  7,670.    Elapsed: 0:15:01.\n",
            "  Batch 2,600  of  7,670.    Elapsed: 0:15:15.\n",
            "  Batch 2,640  of  7,670.    Elapsed: 0:15:29.\n",
            "  Batch 2,680  of  7,670.    Elapsed: 0:15:44.\n",
            "  Batch 2,720  of  7,670.    Elapsed: 0:15:58.\n",
            "  Batch 2,760  of  7,670.    Elapsed: 0:16:12.\n",
            "  Batch 2,800  of  7,670.    Elapsed: 0:16:26.\n",
            "  Batch 2,840  of  7,670.    Elapsed: 0:16:40.\n",
            "  Batch 2,880  of  7,670.    Elapsed: 0:16:54.\n",
            "  Batch 2,920  of  7,670.    Elapsed: 0:17:08.\n",
            "  Batch 2,960  of  7,670.    Elapsed: 0:17:22.\n",
            "  Batch 3,000  of  7,670.    Elapsed: 0:17:36.\n",
            "  Batch 3,040  of  7,670.    Elapsed: 0:17:50.\n",
            "  Batch 3,080  of  7,670.    Elapsed: 0:18:05.\n",
            "  Batch 3,120  of  7,670.    Elapsed: 0:18:19.\n",
            "  Batch 3,160  of  7,670.    Elapsed: 0:18:33.\n",
            "  Batch 3,200  of  7,670.    Elapsed: 0:18:47.\n",
            "  Batch 3,240  of  7,670.    Elapsed: 0:19:01.\n",
            "  Batch 3,280  of  7,670.    Elapsed: 0:19:15.\n",
            "  Batch 3,320  of  7,670.    Elapsed: 0:19:29.\n",
            "  Batch 3,360  of  7,670.    Elapsed: 0:19:43.\n",
            "  Batch 3,400  of  7,670.    Elapsed: 0:19:57.\n",
            "  Batch 3,440  of  7,670.    Elapsed: 0:20:11.\n",
            "  Batch 3,480  of  7,670.    Elapsed: 0:20:25.\n",
            "  Batch 3,520  of  7,670.    Elapsed: 0:20:40.\n",
            "  Batch 3,560  of  7,670.    Elapsed: 0:20:54.\n",
            "  Batch 3,600  of  7,670.    Elapsed: 0:21:08.\n",
            "  Batch 3,640  of  7,670.    Elapsed: 0:21:22.\n",
            "  Batch 3,680  of  7,670.    Elapsed: 0:21:36.\n",
            "  Batch 3,720  of  7,670.    Elapsed: 0:21:50.\n",
            "  Batch 3,760  of  7,670.    Elapsed: 0:22:04.\n",
            "  Batch 3,800  of  7,670.    Elapsed: 0:22:18.\n",
            "  Batch 3,840  of  7,670.    Elapsed: 0:22:32.\n",
            "  Batch 3,880  of  7,670.    Elapsed: 0:22:46.\n",
            "  Batch 3,920  of  7,670.    Elapsed: 0:23:00.\n",
            "  Batch 3,960  of  7,670.    Elapsed: 0:23:15.\n",
            "  Batch 4,000  of  7,670.    Elapsed: 0:23:29.\n",
            "  Batch 4,040  of  7,670.    Elapsed: 0:23:43.\n",
            "  Batch 4,080  of  7,670.    Elapsed: 0:23:57.\n",
            "  Batch 4,120  of  7,670.    Elapsed: 0:24:11.\n",
            "  Batch 4,160  of  7,670.    Elapsed: 0:24:25.\n",
            "  Batch 4,200  of  7,670.    Elapsed: 0:24:39.\n",
            "  Batch 4,240  of  7,670.    Elapsed: 0:24:53.\n",
            "  Batch 4,280  of  7,670.    Elapsed: 0:25:07.\n",
            "  Batch 4,320  of  7,670.    Elapsed: 0:25:21.\n",
            "  Batch 4,360  of  7,670.    Elapsed: 0:25:35.\n",
            "  Batch 4,400  of  7,670.    Elapsed: 0:25:50.\n",
            "  Batch 4,440  of  7,670.    Elapsed: 0:26:04.\n",
            "  Batch 4,480  of  7,670.    Elapsed: 0:26:18.\n",
            "  Batch 4,520  of  7,670.    Elapsed: 0:26:32.\n",
            "  Batch 4,560  of  7,670.    Elapsed: 0:26:46.\n",
            "  Batch 4,600  of  7,670.    Elapsed: 0:27:00.\n",
            "  Batch 4,640  of  7,670.    Elapsed: 0:27:14.\n",
            "  Batch 4,680  of  7,670.    Elapsed: 0:27:28.\n",
            "  Batch 4,720  of  7,670.    Elapsed: 0:27:42.\n",
            "  Batch 4,760  of  7,670.    Elapsed: 0:27:57.\n",
            "  Batch 4,800  of  7,670.    Elapsed: 0:28:11.\n",
            "  Batch 4,840  of  7,670.    Elapsed: 0:28:25.\n",
            "  Batch 4,880  of  7,670.    Elapsed: 0:28:39.\n",
            "  Batch 4,920  of  7,670.    Elapsed: 0:28:53.\n",
            "  Batch 4,960  of  7,670.    Elapsed: 0:29:07.\n",
            "  Batch 5,000  of  7,670.    Elapsed: 0:29:21.\n",
            "  Batch 5,040  of  7,670.    Elapsed: 0:29:35.\n",
            "  Batch 5,080  of  7,670.    Elapsed: 0:29:49.\n",
            "  Batch 5,120  of  7,670.    Elapsed: 0:30:04.\n",
            "  Batch 5,160  of  7,670.    Elapsed: 0:30:18.\n",
            "  Batch 5,200  of  7,670.    Elapsed: 0:30:32.\n",
            "  Batch 5,240  of  7,670.    Elapsed: 0:30:46.\n",
            "  Batch 5,280  of  7,670.    Elapsed: 0:31:00.\n",
            "  Batch 5,320  of  7,670.    Elapsed: 0:31:14.\n",
            "  Batch 5,360  of  7,670.    Elapsed: 0:31:28.\n",
            "  Batch 5,400  of  7,670.    Elapsed: 0:31:42.\n",
            "  Batch 5,440  of  7,670.    Elapsed: 0:31:56.\n",
            "  Batch 5,480  of  7,670.    Elapsed: 0:32:10.\n",
            "  Batch 5,520  of  7,670.    Elapsed: 0:32:25.\n",
            "  Batch 5,560  of  7,670.    Elapsed: 0:32:39.\n",
            "  Batch 5,600  of  7,670.    Elapsed: 0:32:53.\n",
            "  Batch 5,640  of  7,670.    Elapsed: 0:33:07.\n",
            "  Batch 5,680  of  7,670.    Elapsed: 0:33:21.\n",
            "  Batch 5,720  of  7,670.    Elapsed: 0:33:35.\n",
            "  Batch 5,760  of  7,670.    Elapsed: 0:33:49.\n",
            "  Batch 5,800  of  7,670.    Elapsed: 0:34:03.\n",
            "  Batch 5,840  of  7,670.    Elapsed: 0:34:17.\n",
            "  Batch 5,880  of  7,670.    Elapsed: 0:34:32.\n",
            "  Batch 5,920  of  7,670.    Elapsed: 0:34:46.\n",
            "  Batch 5,960  of  7,670.    Elapsed: 0:35:00.\n",
            "  Batch 6,000  of  7,670.    Elapsed: 0:35:14.\n",
            "  Batch 6,040  of  7,670.    Elapsed: 0:35:28.\n",
            "  Batch 6,080  of  7,670.    Elapsed: 0:35:42.\n",
            "  Batch 6,120  of  7,670.    Elapsed: 0:35:56.\n",
            "  Batch 6,160  of  7,670.    Elapsed: 0:36:10.\n",
            "  Batch 6,200  of  7,670.    Elapsed: 0:36:24.\n",
            "  Batch 6,240  of  7,670.    Elapsed: 0:36:38.\n",
            "  Batch 6,280  of  7,670.    Elapsed: 0:36:53.\n",
            "  Batch 6,320  of  7,670.    Elapsed: 0:37:07.\n",
            "  Batch 6,360  of  7,670.    Elapsed: 0:37:21.\n",
            "  Batch 6,400  of  7,670.    Elapsed: 0:37:35.\n",
            "  Batch 6,440  of  7,670.    Elapsed: 0:37:49.\n",
            "  Batch 6,480  of  7,670.    Elapsed: 0:38:03.\n",
            "  Batch 6,520  of  7,670.    Elapsed: 0:38:17.\n",
            "  Batch 6,560  of  7,670.    Elapsed: 0:38:31.\n",
            "  Batch 6,600  of  7,670.    Elapsed: 0:38:45.\n",
            "  Batch 6,640  of  7,670.    Elapsed: 0:38:59.\n",
            "  Batch 6,680  of  7,670.    Elapsed: 0:39:13.\n",
            "  Batch 6,720  of  7,670.    Elapsed: 0:39:27.\n",
            "  Batch 6,760  of  7,670.    Elapsed: 0:39:42.\n",
            "  Batch 6,800  of  7,670.    Elapsed: 0:39:56.\n",
            "  Batch 6,840  of  7,670.    Elapsed: 0:40:10.\n",
            "  Batch 6,880  of  7,670.    Elapsed: 0:40:24.\n",
            "  Batch 6,920  of  7,670.    Elapsed: 0:40:38.\n",
            "  Batch 6,960  of  7,670.    Elapsed: 0:40:52.\n",
            "  Batch 7,000  of  7,670.    Elapsed: 0:41:06.\n",
            "  Batch 7,040  of  7,670.    Elapsed: 0:41:20.\n",
            "  Batch 7,080  of  7,670.    Elapsed: 0:41:34.\n",
            "  Batch 7,120  of  7,670.    Elapsed: 0:41:48.\n",
            "  Batch 7,160  of  7,670.    Elapsed: 0:42:03.\n",
            "  Batch 7,200  of  7,670.    Elapsed: 0:42:17.\n",
            "  Batch 7,240  of  7,670.    Elapsed: 0:42:31.\n",
            "  Batch 7,280  of  7,670.    Elapsed: 0:42:45.\n",
            "  Batch 7,320  of  7,670.    Elapsed: 0:42:59.\n",
            "  Batch 7,360  of  7,670.    Elapsed: 0:43:13.\n",
            "  Batch 7,400  of  7,670.    Elapsed: 0:43:27.\n",
            "  Batch 7,440  of  7,670.    Elapsed: 0:43:41.\n",
            "  Batch 7,480  of  7,670.    Elapsed: 0:43:55.\n",
            "  Batch 7,520  of  7,670.    Elapsed: 0:44:09.\n",
            "  Batch 7,560  of  7,670.    Elapsed: 0:44:24.\n",
            "  Batch 7,600  of  7,670.    Elapsed: 0:44:38.\n",
            "  Batch 7,640  of  7,670.    Elapsed: 0:44:52.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:45:02\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation took: 0:01:37\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  7,670.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  7,670.    Elapsed: 0:00:28.\n",
            "  Batch   120  of  7,670.    Elapsed: 0:00:42.\n",
            "  Batch   160  of  7,670.    Elapsed: 0:00:56.\n",
            "  Batch   200  of  7,670.    Elapsed: 0:01:11.\n",
            "  Batch   240  of  7,670.    Elapsed: 0:01:25.\n",
            "  Batch   280  of  7,670.    Elapsed: 0:01:39.\n",
            "  Batch   320  of  7,670.    Elapsed: 0:01:53.\n",
            "  Batch   360  of  7,670.    Elapsed: 0:02:07.\n",
            "  Batch   400  of  7,670.    Elapsed: 0:02:21.\n",
            "  Batch   440  of  7,670.    Elapsed: 0:02:35.\n",
            "  Batch   480  of  7,670.    Elapsed: 0:02:49.\n",
            "  Batch   520  of  7,670.    Elapsed: 0:03:03.\n",
            "  Batch   560  of  7,670.    Elapsed: 0:03:17.\n",
            "  Batch   600  of  7,670.    Elapsed: 0:03:32.\n",
            "  Batch   640  of  7,670.    Elapsed: 0:03:46.\n",
            "  Batch   680  of  7,670.    Elapsed: 0:04:00.\n",
            "  Batch   720  of  7,670.    Elapsed: 0:04:14.\n",
            "  Batch   760  of  7,670.    Elapsed: 0:04:28.\n",
            "  Batch   800  of  7,670.    Elapsed: 0:04:42.\n",
            "  Batch   840  of  7,670.    Elapsed: 0:04:56.\n",
            "  Batch   880  of  7,670.    Elapsed: 0:05:10.\n",
            "  Batch   920  of  7,670.    Elapsed: 0:05:24.\n",
            "  Batch   960  of  7,670.    Elapsed: 0:05:38.\n",
            "  Batch 1,000  of  7,670.    Elapsed: 0:05:52.\n",
            "  Batch 1,040  of  7,670.    Elapsed: 0:06:07.\n",
            "  Batch 1,080  of  7,670.    Elapsed: 0:06:21.\n",
            "  Batch 1,120  of  7,670.    Elapsed: 0:06:35.\n",
            "  Batch 1,160  of  7,670.    Elapsed: 0:06:49.\n",
            "  Batch 1,200  of  7,670.    Elapsed: 0:07:03.\n",
            "  Batch 1,240  of  7,670.    Elapsed: 0:07:17.\n",
            "  Batch 1,280  of  7,670.    Elapsed: 0:07:31.\n",
            "  Batch 1,320  of  7,670.    Elapsed: 0:07:45.\n",
            "  Batch 1,360  of  7,670.    Elapsed: 0:07:59.\n",
            "  Batch 1,400  of  7,670.    Elapsed: 0:08:13.\n",
            "  Batch 1,440  of  7,670.    Elapsed: 0:08:27.\n",
            "  Batch 1,480  of  7,670.    Elapsed: 0:08:42.\n",
            "  Batch 1,520  of  7,670.    Elapsed: 0:08:56.\n",
            "  Batch 1,560  of  7,670.    Elapsed: 0:09:10.\n",
            "  Batch 1,600  of  7,670.    Elapsed: 0:09:24.\n",
            "  Batch 1,640  of  7,670.    Elapsed: 0:09:38.\n",
            "  Batch 1,680  of  7,670.    Elapsed: 0:09:52.\n",
            "  Batch 1,720  of  7,670.    Elapsed: 0:10:06.\n",
            "  Batch 1,760  of  7,670.    Elapsed: 0:10:20.\n",
            "  Batch 1,800  of  7,670.    Elapsed: 0:10:34.\n",
            "  Batch 1,840  of  7,670.    Elapsed: 0:10:48.\n",
            "  Batch 1,880  of  7,670.    Elapsed: 0:11:02.\n",
            "  Batch 1,920  of  7,670.    Elapsed: 0:11:16.\n",
            "  Batch 1,960  of  7,670.    Elapsed: 0:11:30.\n",
            "  Batch 2,000  of  7,670.    Elapsed: 0:11:45.\n",
            "  Batch 2,040  of  7,670.    Elapsed: 0:11:59.\n",
            "  Batch 2,080  of  7,670.    Elapsed: 0:12:13.\n",
            "  Batch 2,120  of  7,670.    Elapsed: 0:12:27.\n",
            "  Batch 2,160  of  7,670.    Elapsed: 0:12:41.\n",
            "  Batch 2,200  of  7,670.    Elapsed: 0:12:55.\n",
            "  Batch 2,240  of  7,670.    Elapsed: 0:13:09.\n",
            "  Batch 2,280  of  7,670.    Elapsed: 0:13:23.\n",
            "  Batch 2,320  of  7,670.    Elapsed: 0:13:37.\n",
            "  Batch 2,360  of  7,670.    Elapsed: 0:13:51.\n",
            "  Batch 2,400  of  7,670.    Elapsed: 0:14:05.\n",
            "  Batch 2,440  of  7,670.    Elapsed: 0:14:19.\n",
            "  Batch 2,480  of  7,670.    Elapsed: 0:14:34.\n",
            "  Batch 2,520  of  7,670.    Elapsed: 0:14:48.\n",
            "  Batch 2,560  of  7,670.    Elapsed: 0:15:02.\n",
            "  Batch 2,600  of  7,670.    Elapsed: 0:15:16.\n",
            "  Batch 2,640  of  7,670.    Elapsed: 0:15:30.\n",
            "  Batch 2,680  of  7,670.    Elapsed: 0:15:44.\n",
            "  Batch 2,720  of  7,670.    Elapsed: 0:15:58.\n",
            "  Batch 2,760  of  7,670.    Elapsed: 0:16:12.\n",
            "  Batch 2,800  of  7,670.    Elapsed: 0:16:26.\n",
            "  Batch 2,840  of  7,670.    Elapsed: 0:16:40.\n",
            "  Batch 2,880  of  7,670.    Elapsed: 0:16:54.\n",
            "  Batch 2,920  of  7,670.    Elapsed: 0:17:09.\n",
            "  Batch 2,960  of  7,670.    Elapsed: 0:17:23.\n",
            "  Batch 3,000  of  7,670.    Elapsed: 0:17:37.\n",
            "  Batch 3,040  of  7,670.    Elapsed: 0:17:51.\n",
            "  Batch 3,080  of  7,670.    Elapsed: 0:18:05.\n",
            "  Batch 3,120  of  7,670.    Elapsed: 0:18:19.\n",
            "  Batch 3,160  of  7,670.    Elapsed: 0:18:33.\n",
            "  Batch 3,200  of  7,670.    Elapsed: 0:18:47.\n",
            "  Batch 3,240  of  7,670.    Elapsed: 0:19:01.\n",
            "  Batch 3,280  of  7,670.    Elapsed: 0:19:15.\n",
            "  Batch 3,320  of  7,670.    Elapsed: 0:19:29.\n",
            "  Batch 3,360  of  7,670.    Elapsed: 0:19:43.\n",
            "  Batch 3,400  of  7,670.    Elapsed: 0:19:58.\n",
            "  Batch 3,440  of  7,670.    Elapsed: 0:20:12.\n",
            "  Batch 3,480  of  7,670.    Elapsed: 0:20:26.\n",
            "  Batch 3,520  of  7,670.    Elapsed: 0:20:40.\n",
            "  Batch 3,560  of  7,670.    Elapsed: 0:20:54.\n",
            "  Batch 3,600  of  7,670.    Elapsed: 0:21:08.\n",
            "  Batch 3,640  of  7,670.    Elapsed: 0:21:22.\n",
            "  Batch 3,680  of  7,670.    Elapsed: 0:21:36.\n",
            "  Batch 3,720  of  7,670.    Elapsed: 0:21:50.\n",
            "  Batch 3,760  of  7,670.    Elapsed: 0:22:04.\n",
            "  Batch 3,800  of  7,670.    Elapsed: 0:22:18.\n",
            "  Batch 3,840  of  7,670.    Elapsed: 0:22:32.\n",
            "  Batch 3,880  of  7,670.    Elapsed: 0:22:46.\n",
            "  Batch 3,920  of  7,670.    Elapsed: 0:23:01.\n",
            "  Batch 3,960  of  7,670.    Elapsed: 0:23:15.\n",
            "  Batch 4,000  of  7,670.    Elapsed: 0:23:29.\n",
            "  Batch 4,040  of  7,670.    Elapsed: 0:23:43.\n",
            "  Batch 4,080  of  7,670.    Elapsed: 0:23:57.\n",
            "  Batch 4,120  of  7,670.    Elapsed: 0:24:11.\n",
            "  Batch 4,160  of  7,670.    Elapsed: 0:24:25.\n",
            "  Batch 4,200  of  7,670.    Elapsed: 0:24:39.\n",
            "  Batch 4,240  of  7,670.    Elapsed: 0:24:53.\n",
            "  Batch 4,280  of  7,670.    Elapsed: 0:25:07.\n",
            "  Batch 4,320  of  7,670.    Elapsed: 0:25:21.\n",
            "  Batch 4,360  of  7,670.    Elapsed: 0:25:35.\n",
            "  Batch 4,400  of  7,670.    Elapsed: 0:25:49.\n",
            "  Batch 4,440  of  7,670.    Elapsed: 0:26:03.\n",
            "  Batch 4,480  of  7,670.    Elapsed: 0:26:18.\n",
            "  Batch 4,520  of  7,670.    Elapsed: 0:26:32.\n",
            "  Batch 4,560  of  7,670.    Elapsed: 0:26:46.\n",
            "  Batch 4,600  of  7,670.    Elapsed: 0:27:00.\n",
            "  Batch 4,640  of  7,670.    Elapsed: 0:27:14.\n",
            "  Batch 4,680  of  7,670.    Elapsed: 0:27:28.\n",
            "  Batch 4,720  of  7,670.    Elapsed: 0:27:42.\n",
            "  Batch 4,760  of  7,670.    Elapsed: 0:27:56.\n",
            "  Batch 4,800  of  7,670.    Elapsed: 0:28:10.\n",
            "  Batch 4,840  of  7,670.    Elapsed: 0:28:24.\n",
            "  Batch 4,880  of  7,670.    Elapsed: 0:28:38.\n",
            "  Batch 4,920  of  7,670.    Elapsed: 0:28:52.\n",
            "  Batch 4,960  of  7,670.    Elapsed: 0:29:06.\n",
            "  Batch 5,000  of  7,670.    Elapsed: 0:29:21.\n",
            "  Batch 5,040  of  7,670.    Elapsed: 0:29:35.\n",
            "  Batch 5,080  of  7,670.    Elapsed: 0:29:49.\n",
            "  Batch 5,120  of  7,670.    Elapsed: 0:30:03.\n",
            "  Batch 5,160  of  7,670.    Elapsed: 0:30:17.\n",
            "  Batch 5,200  of  7,670.    Elapsed: 0:30:31.\n",
            "  Batch 5,240  of  7,670.    Elapsed: 0:30:45.\n",
            "  Batch 5,280  of  7,670.    Elapsed: 0:30:59.\n",
            "  Batch 5,320  of  7,670.    Elapsed: 0:31:13.\n",
            "  Batch 5,360  of  7,670.    Elapsed: 0:31:27.\n",
            "  Batch 5,400  of  7,670.    Elapsed: 0:31:41.\n",
            "  Batch 5,440  of  7,670.    Elapsed: 0:31:56.\n",
            "  Batch 5,480  of  7,670.    Elapsed: 0:32:10.\n",
            "  Batch 5,520  of  7,670.    Elapsed: 0:32:24.\n",
            "  Batch 5,560  of  7,670.    Elapsed: 0:32:38.\n",
            "  Batch 5,600  of  7,670.    Elapsed: 0:32:52.\n",
            "  Batch 5,640  of  7,670.    Elapsed: 0:33:06.\n",
            "  Batch 5,680  of  7,670.    Elapsed: 0:33:20.\n",
            "  Batch 5,720  of  7,670.    Elapsed: 0:33:34.\n",
            "  Batch 5,760  of  7,670.    Elapsed: 0:33:48.\n",
            "  Batch 5,800  of  7,670.    Elapsed: 0:34:02.\n",
            "  Batch 5,840  of  7,670.    Elapsed: 0:34:16.\n",
            "  Batch 5,880  of  7,670.    Elapsed: 0:34:30.\n",
            "  Batch 5,920  of  7,670.    Elapsed: 0:34:44.\n",
            "  Batch 5,960  of  7,670.    Elapsed: 0:34:59.\n",
            "  Batch 6,000  of  7,670.    Elapsed: 0:35:13.\n",
            "  Batch 6,040  of  7,670.    Elapsed: 0:35:27.\n",
            "  Batch 6,080  of  7,670.    Elapsed: 0:35:41.\n",
            "  Batch 6,120  of  7,670.    Elapsed: 0:35:55.\n",
            "  Batch 6,160  of  7,670.    Elapsed: 0:36:09.\n",
            "  Batch 6,200  of  7,670.    Elapsed: 0:36:23.\n",
            "  Batch 6,240  of  7,670.    Elapsed: 0:36:37.\n",
            "  Batch 6,280  of  7,670.    Elapsed: 0:36:51.\n",
            "  Batch 6,320  of  7,670.    Elapsed: 0:37:05.\n",
            "  Batch 6,360  of  7,670.    Elapsed: 0:37:19.\n",
            "  Batch 6,400  of  7,670.    Elapsed: 0:37:34.\n",
            "  Batch 6,440  of  7,670.    Elapsed: 0:37:48.\n",
            "  Batch 6,480  of  7,670.    Elapsed: 0:38:02.\n",
            "  Batch 6,520  of  7,670.    Elapsed: 0:38:16.\n",
            "  Batch 6,560  of  7,670.    Elapsed: 0:38:30.\n",
            "  Batch 6,600  of  7,670.    Elapsed: 0:38:44.\n",
            "  Batch 6,640  of  7,670.    Elapsed: 0:38:58.\n",
            "  Batch 6,680  of  7,670.    Elapsed: 0:39:12.\n",
            "  Batch 6,720  of  7,670.    Elapsed: 0:39:26.\n",
            "  Batch 6,760  of  7,670.    Elapsed: 0:39:40.\n",
            "  Batch 6,800  of  7,670.    Elapsed: 0:39:54.\n",
            "  Batch 6,840  of  7,670.    Elapsed: 0:40:08.\n",
            "  Batch 6,880  of  7,670.    Elapsed: 0:40:22.\n",
            "  Batch 6,920  of  7,670.    Elapsed: 0:40:37.\n",
            "  Batch 6,960  of  7,670.    Elapsed: 0:40:51.\n",
            "  Batch 7,000  of  7,670.    Elapsed: 0:41:05.\n",
            "  Batch 7,040  of  7,670.    Elapsed: 0:41:19.\n",
            "  Batch 7,080  of  7,670.    Elapsed: 0:41:33.\n",
            "  Batch 7,120  of  7,670.    Elapsed: 0:41:47.\n",
            "  Batch 7,160  of  7,670.    Elapsed: 0:42:01.\n",
            "  Batch 7,200  of  7,670.    Elapsed: 0:42:15.\n",
            "  Batch 7,240  of  7,670.    Elapsed: 0:42:29.\n",
            "  Batch 7,280  of  7,670.    Elapsed: 0:42:43.\n",
            "  Batch 7,320  of  7,670.    Elapsed: 0:42:57.\n",
            "  Batch 7,360  of  7,670.    Elapsed: 0:43:11.\n",
            "  Batch 7,400  of  7,670.    Elapsed: 0:43:25.\n",
            "  Batch 7,440  of  7,670.    Elapsed: 0:43:39.\n",
            "  Batch 7,480  of  7,670.    Elapsed: 0:43:54.\n",
            "  Batch 7,520  of  7,670.    Elapsed: 0:44:08.\n",
            "  Batch 7,560  of  7,670.    Elapsed: 0:44:22.\n",
            "  Batch 7,600  of  7,670.    Elapsed: 0:44:36.\n",
            "  Batch 7,640  of  7,670.    Elapsed: 0:44:50.\n",
            "\n",
            "  Average training loss: 0.48\n",
            "  Training epcoh took: 0:45:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation took: 0:01:37\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "zBWy7Q6yN5g1",
        "outputId": "7ee3ecf6-7385-4d47-98fc-0e15f0227e24"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRqyYTUiOAM6"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AUTH_PROF_BERT DataSet/bert_test.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxOlGHYtPvbc"
      },
      "source": [
        "dss = df['sentence'].tolist()\n",
        "\n",
        "\n",
        "dss = [\" \".join([stemmer.stem(word) for word in sentence.split(\" \")]) for sentence in dss]\n",
        "dss = [\" \".join([lemmatizer.lemmatize(word) for word in sentence.split(\" \")]) for sentence in dss]\n",
        "\n",
        "df['sentence'] = dss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ZEpArLQqPzH0",
        "outputId": "ea5975ab-acad-43aa-b5e7-729c66ab8ee0"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>189995</th>\n",
              "      <td>fff5a17288a8ab173e493c90bf4b39a4.csv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hair hardest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189996</th>\n",
              "      <td>fff5a17288a8ab173e493c90bf4b39a4.csv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>saw seal wild tell happi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189997</th>\n",
              "      <td>fff5a17288a8ab173e493c90bf4b39a4.csv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>note up get readi way bed asleep omg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189998</th>\n",
              "      <td>fff5a17288a8ab173e493c90bf4b39a4.csv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>happi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189999</th>\n",
              "      <td>fff5a17288a8ab173e493c90bf4b39a4.csv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>but thank hope year marvel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           ID  ...                              sentence\n",
              "189995  fff5a17288a8ab173e493c90bf4b39a4.csv   ...                          hair hardest\n",
              "189996  fff5a17288a8ab173e493c90bf4b39a4.csv   ...              saw seal wild tell happi\n",
              "189997  fff5a17288a8ab173e493c90bf4b39a4.csv   ...  note up get readi way bed asleep omg\n",
              "189998  fff5a17288a8ab173e493c90bf4b39a4.csv   ...                                 happi\n",
              "189999  fff5a17288a8ab173e493c90bf4b39a4.csv   ...            but thank hope year marvel\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ky-HTC1OSFxi",
        "outputId": "8bcbd528-bb80-4766-c484-4207095abd7a"
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 190,000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFU93m3mSMrN",
        "outputId": "822e72a5-c0fa-4db0-84b5-bdb299a4aa44"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 190,000 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5oe3QHbTC6U"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cETpV3ptTJnj",
        "outputId": "d445c1e1-0b37-4776-f66a-59905a825ee7"
      },
      "source": [
        "len(flat_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSVav87wTNQt"
      },
      "source": [
        "from collections import Counter \n",
        "  \n",
        "def most_frequent(List): \n",
        "    occurence_count = Counter(List) \n",
        "    return occurence_count.most_common(1)[0][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dD7dRnYTQ41"
      },
      "source": [
        "chunks = [flat_predictions[x:x+100] for x in range(0, len(flat_predictions),100)]\n",
        "gender=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCbHmhM_TU7y"
      },
      "source": [
        "for i in chunks:\n",
        "    gender.append(most_frequent(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoRy-uI9TY5a",
        "outputId": "0eff479f-2417-4515-dee1-20030dc02394"
      },
      "source": [
        "len(gender)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1900"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoGsY-TITdcU"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "btest = pd.read_csv(\"/content/drive/MyDrive/AUTH_PROF_BERT DataSet/bert_test_labels.csv\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq8tWzosTpdJ"
      },
      "source": [
        "btest['bert_gender'] = gender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoQOqCGWTrME"
      },
      "source": [
        "btest.loc[btest.gender == 'male', 'gender'] = 1\n",
        "btest.loc[btest.gender == 'female', 'gender'] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "PjsiLmtXTw_Q",
        "outputId": "fefb1592-d44c-4365-bef6-9c1e9610b012"
      },
      "source": [
        "btest.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>gender</th>\n",
              "      <th>buffer</th>\n",
              "      <th>bert_gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100c885443c4d2a32075e10cbca9a27e.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>100c885443c4d2a32075e10cbca9a27e</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1017647e21e7e73d900e1dfacbf95a0f.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>1017647e21e7e73d900e1dfacbf95a0f</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1023e1e534622e28d29dfdc0ee45cdac.csv</td>\n",
              "      <td>1</td>\n",
              "      <td>1023e1e534622e28d29dfdc0ee45cdac</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10283d7f37d33b063e3734b740f5229d.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>10283d7f37d33b063e3734b740f5229d</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1069f66c9d5862f860277d32780ac459.csv</td>\n",
              "      <td>0</td>\n",
              "      <td>1069f66c9d5862f860277d32780ac459</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     ID  ... bert_gender\n",
              "0  100c885443c4d2a32075e10cbca9a27e.csv  ...           0\n",
              "1  1017647e21e7e73d900e1dfacbf95a0f.csv  ...           1\n",
              "2  1023e1e534622e28d29dfdc0ee45cdac.csv  ...           1\n",
              "3  10283d7f37d33b063e3734b740f5229d.csv  ...           0\n",
              "4  1069f66c9d5862f860277d32780ac459.csv  ...           0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NZmKGYLT2S9",
        "outputId": "3bf7783c-6c63-4d1a-ee3f-cdc6b6609cd7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_true = btest['gender'].tolist()\n",
        "y_pred = btest['bert_gender'].tolist()\n",
        "\n",
        "print('The accuracy from the Bert classifier is,',accuracy_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy from the Bert classifier is, 0.7705263157894737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOvNlLBmT_9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af73c175-7f6e-4ab0-90c3-75307c51d5f6"
      },
      "source": [
        "from sklearn import metrics\n",
        "print(\"Some basic stastistical measures for this model are\")\n",
        "print(metrics.classification_report(y_true, y_pred))\n",
        " \n",
        "print(\"The Confusion Matrix is\")\n",
        "print(metrics.confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some basic stastistical measures for this model are\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.81      0.78       940\n",
            "           1       0.80      0.73      0.76       960\n",
            "\n",
            "    accuracy                           0.77      1900\n",
            "   macro avg       0.77      0.77      0.77      1900\n",
            "weighted avg       0.77      0.77      0.77      1900\n",
            "\n",
            "The Confusion Matrix is\n",
            "[[765 175]\n",
            " [261 699]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}